import { prompts } from '../config/prompts';
import { logger } from '../utils/logger';

jest.mock('../utils/logger');

const mockCreate = jest.fn();
const mockOpenAI = jest.fn().mockImplementation(() => ({
  chat: {
    completions: {
      create: mockCreate,
    },
  },
}));

jest.mock('openai', () => mockOpenAI);

import {
  generatePostContent,
  generateCommentReply,
  resetOpenAIClient,
} from './openaiService';

describe('openaiService', () => {
  beforeEach(() => {
    mockCreate.mockClear();
    mockOpenAI.mockClear();
    resetOpenAIClient();
  });

  describe('generatePostContent', () => {
    it('should generate stock post content with correct prompt', async () => {
      const mockResponse = {
        choices: [
          {
            message: {
              content: 'ðŸ“Š ì‚¼ì„±ì „ìž ì£¼ê°€ ë¶„ì„...',
            },
          },
        ],
        usage: {
          prompt_tokens: 100,
          completion_tokens: 200,
          total_tokens: 300,
        },
      };

      mockCreate.mockResolvedValue(mockResponse);

      const result = await generatePostContent('stock', 'ì‚¼ì„±ì „ìž ìµœê·¼ ë‰´ìŠ¤');

      expect(mockCreate).toHaveBeenCalled();
      expect(result).toBe('ðŸ“Š ì‚¼ì„±ì „ìž ì£¼ê°€ ë¶„ì„...');
      expect(mockCreate).toHaveBeenCalledWith({
        model: expect.any(String),
        messages: [
          { role: 'system', content: prompts.stockPost },
          { role: 'user', content: 'ì‚¼ì„±ì „ìž ìµœê·¼ ë‰´ìŠ¤' },
        ],
        temperature: 0.7,
        max_tokens: 1500,
      });
      expect(logger.info).toHaveBeenCalledWith(
        expect.stringContaining('stock post'),
      );
    });

    it('should generate politics post content with correct prompt', async () => {
      const mockResponse = {
        choices: [
          {
            message: {
              content: 'ðŸ›ï¸ ì˜¤ëŠ˜ì˜ ì •ì¹˜ ë‰´ìŠ¤...',
            },
          },
        ],
        usage: {
          prompt_tokens: 120,
          completion_tokens: 250,
          total_tokens: 370,
        },
      };

      mockCreate.mockResolvedValue(mockResponse);

      const result = await generatePostContent('politics', 'ì •ì¹˜ ë‰´ìŠ¤ ë°ì´í„°');

      expect(result).toBe('ðŸ›ï¸ ì˜¤ëŠ˜ì˜ ì •ì¹˜ ë‰´ìŠ¤...');
      expect(mockCreate).toHaveBeenCalledWith({
        model: expect.any(String),
        messages: [
          { role: 'system', content: prompts.politicsPost },
          { role: 'user', content: 'ì •ì¹˜ ë‰´ìŠ¤ ë°ì´í„°' },
        ],
        temperature: 0.7,
        max_tokens: 1500,
      });
      expect(logger.info).toHaveBeenCalledWith(
        expect.stringContaining('politics post'),
      );
    });

    it('should generate news post content with correct prompt', async () => {
      const mockResponse = {
        choices: [
          {
            message: {
              content: 'ðŸ“° ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤...',
            },
          },
        ],
        usage: {
          prompt_tokens: 150,
          completion_tokens: 300,
          total_tokens: 450,
        },
      };

      mockCreate.mockResolvedValue(mockResponse);

      const result = await generatePostContent('news', 'ì¼ë°˜ ë‰´ìŠ¤ ë°ì´í„°');

      expect(result).toBe('ðŸ“° ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤...');
      expect(mockCreate).toHaveBeenCalledWith({
        model: expect.any(String),
        messages: [
          { role: 'system', content: prompts.newsPost },
          { role: 'user', content: 'ì¼ë°˜ ë‰´ìŠ¤ ë°ì´í„°' },
        ],
        temperature: 0.7,
        max_tokens: 1500,
      });
      expect(logger.info).toHaveBeenCalledWith(
        expect.stringContaining('news post'),
      );
    });

    it('should return null on OpenAI API failure', async () => {
      mockCreate.mockRejectedValue(new Error('API Error'));

      const result = await generatePostContent('stock', 'í…ŒìŠ¤íŠ¸ ë°ì´í„°');

      expect(result).toBeNull();
      expect(logger.error).toHaveBeenCalledWith(
        expect.stringContaining('Failed to generate stock post'),
        expect.any(Error),
      );
    });

    it('should log token usage', async () => {
      const mockResponse = {
        choices: [
          {
            message: {
              content: 'Test content',
            },
          },
        ],
        usage: {
          prompt_tokens: 100,
          completion_tokens: 200,
          total_tokens: 300,
        },
      };

      mockCreate.mockResolvedValue(mockResponse);

      await generatePostContent('stock', 'test data');

      expect(logger.info).toHaveBeenCalledWith(
        expect.stringMatching(/prompt=100.*completion=200.*total=300/),
      );
    });
  });

  describe('generateCommentReply', () => {
    it('should generate reply with post content and comment thread', async () => {
      const mockResponse = {
        choices: [
          {
            message: {
              content: 'ì¢‹ì€ ì§ˆë¬¸ìž…ë‹ˆë‹¤. ì£¼ê°€ëŠ”...',
            },
          },
        ],
        usage: {
          prompt_tokens: 80,
          completion_tokens: 120,
          total_tokens: 200,
        },
      };

      mockCreate.mockResolvedValue(mockResponse);

      const postContent = 'ðŸ“Š ì‚¼ì„±ì „ìž ì£¼ê°€ ìƒìŠ¹';
      const commentThread = [
        { nickname: 'ì•„ë¹ ', content: 'ì¢‹ì€ ì •ë³´ë„¤ìš”', role: 'user' },
        { nickname: 'stock-bot', content: 'ê°ì‚¬í•©ë‹ˆë‹¤', role: 'assistant' },
      ];
      const userComment = 'ë‚´ì¼ë„ ì˜¤ë¥¼ê¹Œìš”?';

      const result = await generateCommentReply(
        'stock',
        postContent,
        commentThread,
        userComment,
      );

      expect(result).toBe('ì¢‹ì€ ì§ˆë¬¸ìž…ë‹ˆë‹¤. ì£¼ê°€ëŠ”...');
      expect(mockCreate).toHaveBeenCalledWith({
        model: expect.any(String),
        messages: [
          { role: 'system', content: prompts.stockReply },
          {
            role: 'user',
            content: expect.stringContaining(postContent),
          },
        ],
        temperature: 0.7,
        max_tokens: 500,
      });

      const userMessageArg = mockCreate.mock.calls[0][0].messages[1].content;
      expect(userMessageArg).toContain('ê²Œì‹œë¬¼ ë‚´ìš©:');
      expect(userMessageArg).toContain(postContent);
      expect(userMessageArg).toContain('ëŒ“ê¸€ ë§¥ë½:');
      expect(userMessageArg).toContain('[user] ì•„ë¹ : ì¢‹ì€ ì •ë³´ë„¤ìš”');
      expect(userMessageArg).toContain('[assistant] stock-bot: ê°ì‚¬í•©ë‹ˆë‹¤');
      expect(userMessageArg).toContain('ìƒˆ ëŒ“ê¸€: ë‚´ì¼ë„ ì˜¤ë¥¼ê¹Œìš”?');
    });

    it('should return null on OpenAI API failure', async () => {
      mockCreate.mockRejectedValue(new Error('API Error'));

      const result = await generateCommentReply(
        'politics',
        'ê²Œì‹œë¬¼ ë‚´ìš©',
        [],
        'ëŒ“ê¸€',
      );

      expect(result).toBeNull();
      expect(logger.error).toHaveBeenCalledWith(
        expect.stringContaining('Failed to generate politics comment reply'),
        expect.any(Error),
      );
    });

    it('should log token usage for replies', async () => {
      const mockResponse = {
        choices: [
          {
            message: {
              content: 'Reply content',
            },
          },
        ],
        usage: {
          prompt_tokens: 80,
          completion_tokens: 120,
          total_tokens: 200,
        },
      };

      mockCreate.mockResolvedValue(mockResponse);

      await generateCommentReply('news', 'Post content', [], 'User comment');

      expect(logger.info).toHaveBeenCalledWith(
        expect.stringMatching(/news reply.*prompt=80.*completion=120.*total=200/),
      );
    });
  });
});
